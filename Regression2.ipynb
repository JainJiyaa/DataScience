{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bccd6de-bf73-4f80-8d09-55c0214eeecd",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "represent?\n",
    "\n",
    "Calculation- 1-Sum of square residual(error)/Sum of square total(we calculate the average)\n",
    "It ranges between 0 to 1. In this, it doesnt see any importance of feature that it is important or not it will just increase the accuracy as the new feature is added.\n",
    "R-squared is a statistical measure that indicates how much of the variation of a dependent variable is explained by an independent variable in a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccde68-c869-413d-94a3-bb9ccd0b4fc6",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared.\n",
    "\n",
    "Adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model. \n",
    "Typically, the adjusted R-squared is positive, not negative. It is always lower than the R-squared.\n",
    "In this, it will decrease the accuracy point if the particular feature is not important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46684e-bfcb-48c7-bd96-2ba6e8431afa",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "It is more appropriate when there are multiple variables in the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d538558-06cf-4061-b6b4-4d3c6a3bfa04",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?\n",
    "\n",
    "RMSE-It measures the average difference between values predicted by a model and the actual values. In this, we find the root of MSE.\n",
    "The sum of the squared differences between the predicted and observed values is divided by the number of observations, and the square root of the result is taken to yield the RMSE.\n",
    "\n",
    "MSE-The equation here is known as quadratic equation.It helps to convergence and to calculate the slope of any point. We calculate the error by squaring. We use gradient.\n",
    "Mean squared error is calculated by squaring the residual errors of each data point, summing the squared errors, and dividing the sum by the total number of data points.\n",
    "\n",
    "MAE-The MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables.\n",
    "MAE is calculated as the sum of absolute errors divided by the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1af921-ebd3-4757-b4dc-a8a3923b4d12",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis.\n",
    "\n",
    "MSE:\n",
    "Advantages:\n",
    "              1. Equation is differentiable.(we have to calculate the slope then we can find the convergence)\n",
    "              2. It has only one local and global minima.\n",
    "            Disadvantages:\n",
    "              1. Not robust to outliers.\n",
    "              2. It is not in the same unit.\n",
    "              \n",
    "MAE:\n",
    "Advantages:\n",
    "               1. Robust to outlier.\n",
    "               2. It will be in the same unit.\n",
    "             Disadvantages:\n",
    "               1. Convergence usually takes more time.\n",
    "               \n",
    "RMSE:\n",
    " Advantages:\n",
    "                 1. Same unit.\n",
    "                 2. Differentiable.\n",
    "               Disadvantages:\n",
    "                 1. Not robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260e526-1584-4345-8635-89cada89ff86",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?\n",
    "\n",
    "Lasso regression—also known as L1 regularization—is a form of regularization for linear regression models. Regularization is a statistical method to reduce errors caused by overfitting on training data.\n",
    "Lasso regression is a regularization technique that applies a penalty to prevent overfitting and enhance the accuracy of statistical models.\n",
    "Main difference:Ridge regression can handle multicollinearity in the input data by reducing the impact of correlated features on the coefficients, while Lasso regression automatically selects the most important features for prediction.\n",
    "Use:when dealing with datasets containing numerous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e9dec-5d79-4117-86b9-fc1cbf9ddaea",
   "metadata": {},
   "source": [
    "Q7. How do regularized linear models help to prevent overfitting in machine learning?\n",
    "\n",
    "Improves model generalization by reducing overfitting. Regularized models learn underlying patterns, while overfit models memorize noise in training data.\n",
    "Regularization techniques such as L1 (Lasso) L1 regularization simplifies models and improves interpretability by reducing coefficients of less important features to zero.\n",
    "It improves model performance by preventing excessive weighting of outliers or irrelevant features.\n",
    "It introduces hyperparameters (e.g., alpha or lambda) that control the strength of regularization. This allows fine-tuning models to achieve the right balance between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da2af0-1f3e-432f-b3a5-edf46644771b",
   "metadata": {},
   "source": [
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis.\n",
    "\n",
    "The limitations of Regularization are: Regularization can make the model too simple and unsuitable for the data if the regularization parameter is too large. This can cause the model to miss important patterns in the data.\n",
    "Regularization will almost always hurt your training error - that's expected. Without regularization in place, the training algorithm will typically try to minimize the training error independent of any other consideration.\n",
    "So, thats why they may not always be best choice for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269d902-8f94-46f2-8d32-34f15a30ac70",
   "metadata": {},
   "source": [
    "Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?\n",
    "\n",
    "RMSE: RMSE gives more weight to larger errors due to the squaring operation. This can be advantageous when significant errors are particularly undesirable. However, RMSE is sensitive to outliers and can be influenced by extreme values, which might not reflect the overall model performance accurately.\n",
    "\n",
    "MAE: MAE represents the average magnitude of errors, giving equal weight to all errors. It is less sensitive to outliers and can provide a more robust assessment of overall prediction accuracy.\n",
    "\n",
    "Comparing the two models:- \n",
    "-Model A has a lower RMSE (10), indicating that it might perform better when large errors are of particular concern.\n",
    "-Model B has a lower MAE (8), suggesting that it might perform better in terms of overall average prediction accuracy.\n",
    "\n",
    "\n",
    "Since both RMSE and MAE have their strengths and weaknesses, the choice of the better model depends on the specific goals of the analysis and the relative importance of minimizing large errors versus achieving a more balanced average prediction accuracy.\n",
    "\n",
    "LIMITATIONS:\n",
    ". Domain Context: The choice of metric should consider the context of the problem.\n",
    ". Outlier Sensitivity: RMSE can be strongly affected by outliers due to the squaring operation. \n",
    ". Model Complexity: Metrics should be interpreted alongside model complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
