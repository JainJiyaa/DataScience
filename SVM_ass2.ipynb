{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e347ad-2279-4495-8b67-10b8c3ce0aa3",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "\n",
    "In machine learning, polynomial functions and kernel functions are related in the context of kernel methods, such as Support Vector Machines (SVMs). Polynomial kernel functions are a specific type of kernel that enable the transformation of data into a higher-dimensional space where it becomes more separable. This is achieved without explicitly computing the coordinates in the higher-dimensional space, which is computationally efficient. The polynomial kernel essentially allows algorithms to model non-linear relationships by considering polynomial combinations of the original features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b9f26-b17c-4cd5-81a1-70a89e9822a4",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9baafa93-6598-474d-a87c-737f029fd284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries:\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Load and split the dataset:\n",
    "# Example with Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Create and train the SVM model with a polynomial kernel:\n",
    "svm_poly = SVC(kernel='poly', degree=3)  # degree can be adjusted\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions and evaluate the model:\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d6390-5e4f-4a2b-977d-6e71f62e424d",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "In Support Vector Regression (SVR), increasing the value of epsilon (ε) in the ε-insensitive loss function allows for a larger margin of error where no penalty is given for errors. This results in fewer data points falling outside the margin, leading to fewer support vectors. Essentially, a higher epsilon value makes the model less sensitive to small errors, reducing the number of support vectors needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4a73d-6d54-41fc-8907-0ff40d01105d",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    " Support Vector Regression (SVR), the performance is influenced by the choice of kernel function, C parameter, epsilon (ε) parameter, and gamma parameter. Here's a brief explanation of each:\n",
    "\n",
    "Kernel Function:\n",
    "\n",
    "Effect: Determines the transformation of the input space into a higher-dimensional space.\n",
    "Common Choices: Linear, polynomial, radial basis function (RBF).\n",
    "When to Adjust:\n",
    "Use a linear kernel for linearly separable data.\n",
    "Use polynomial or RBF kernels for more complex, non-linear data patterns.\n",
    "\n",
    "C Parameter:\n",
    "Effect: Controls the trade-off between achieving a low training error and a low testing error (generalization).\n",
    "High C: Less tolerant to errors, may lead to overfitting.\n",
    "Low C: More tolerant to errors, may lead to underfitting.\n",
    "When to Adjust:\n",
    "Increase C if the model is underfitting.\n",
    "Decrease C if the model is overfitting.\n",
    "Epsilon (ε) \n",
    "\n",
    "Parameter:\n",
    "Effect: Defines a margin of tolerance where no penalty is given for errors.\n",
    "High ε: Larger margin, fewer support vectors, may ignore small variations.\n",
    "Low ε: Smaller margin, more support vectors, captures more details.\n",
    "When to Adjust:\n",
    "Increase ε if the model is too sensitive to noise (overfitting).\n",
    "Decrease ε if the model is not capturing enough details (underfitting).\n",
    "\n",
    "Gamma Parameter (for RBF and polynomial kernels):\n",
    "Effect: Defines the influence of a single training example.\n",
    "High Gamma: Points closer to each other have more influence, may lead to overfitting.\n",
    "Low Gamma: Points farther apart have more influence, may lead to underfitting.\n",
    "When to Adjust:\n",
    "Increase gamma if the model is underfitting.\n",
    "Decrease gamma if the model is overfitting.\n",
    "Examples of Adjustments:\n",
    "Complex Patterns: Use RBF kernel, high C, low ε, high gamma.\n",
    "Noisy Data: Use RBF kernel, low C, high ε, low gamma.\n",
    "Linear Data: Use linear kernel, moderate C, moderate ε (gamma not applicable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f44bfd-acdb-4c17-8813-f04ea0e33504",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa9e10-b893-4b6d-9b7d-935cd7b24a44",
   "metadata": {},
   "outputs": [],
   "source": [
    " Import Libraries and Load Dataset\n",
    "python\n",
    "Copy code\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "data = datasets.load_iris()\n",
    "X, y = data.data, data.target\n",
    "2. Split the Dataset\n",
    "python\n",
    "Copy code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "3. Preprocess the Data\n",
    "python\n",
    "Copy code\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "4. Train the SVC Classifier\n",
    "python\n",
    "Copy code\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "5. Predict and Evaluate\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "6. Hyperparameter Tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "7. Train Tuned Classifier on Entire Dataset\n",
    "best_svc = grid.best_estimator_\n",
    "best_svc.fit(X, y)\n",
    "\n",
    "8. Save the Trained Classifier\n",
    "joblib.dump(best_svc, 'svc_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88d8b2-e413-4f4b-84f2-f08beaf28537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
